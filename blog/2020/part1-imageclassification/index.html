<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Part 1 - Introducing TensorFlow Datasets in YonoHub Suit — Image Classification with YonoHub &amp; Tensorflow V2.0 Series | Ahmed M. Hendawy </title> <meta name="author" content="Ahmed M. Hendawy"> <meta name="description" content="TensorFlow Datasets is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks. YonoHub encapsulates the datasets in the form of blocks."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8F%B9&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="ahmedhendawy.de/blog/2020/part1-imageclassification/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ahmed </span> M.  Hendawy </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Part 1 - Introducing TensorFlow Datasets in YonoHub Suit — Image Classification with YonoHub &amp; Tensorflow V2.0 Series</h1> <p class="post-meta"> April 29, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/image-classification"> <i class="fa-solid fa-hashtag fa-sm"></i> Image_Classification</a>   <a href="/blog/tag/tensorflow"> <i class="fa-solid fa-hashtag fa-sm"></i> Tensorflow</a>     ·   <a href="/blog/category/yonohub"> <i class="fa-solid fa-tag fa-sm"></i> Yonohub</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p align="center"> <img src="https://miro.medium.com/max/700/1*LXoagPOK5PvBzt_ni_8d-A.jpeg" width="800px" title="Tensorflow Series" alt="Tensorflow Series"> </p> <p>Over the past few years, researchers struggled to find suitable datasets that fit well in their applications. Recently, we were hit by a data storm which enriches our pockets with plenty of datasets which make the job done. However, such a storm has a double-sided effect as we consume a painful time writing different scripts to extract and manipulate these data.</p> <p>On February 26, 2019, Tensorflow had announced <a href="https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html" rel="external nofollow noopener" target="_blank">Tensorflow Datasets </a>(<a href="https://github.com/tensorflow/datase" rel="external nofollow noopener" target="_blank">GitHub </a>) which as I quote,</p> <blockquote> <p>exposes public research datasets as <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="external nofollow noopener" target="_blank"><em>tf.data.Datasets</em></a> and as NumPy arrays. It does all the grungy work of fetching the source data and preparing it into a common format on disk, and it uses the <a href="https://www.tensorflow.org/guide/datasets" rel="external nofollow noopener" target="_blank"><em>tf.data API</em></a> to build high-performance input pipelines, which are TensorFlow 2.0-ready and can be used with <em>tf.keras</em> models.</p> </blockquote> <p>Thus, we have a usable high-level layer we can use to call many datasets in a fast way. But can we do better? Can we have an extra layer that even remove the process of writing a line of code?</p> <p><a href="https://yonohub.com/yonoarc/" rel="external nofollow noopener" target="_blank">YonoArc</a> in the <a href="https://yonohub.com/" rel="external nofollow noopener" target="_blank">YonoHub</a> platform provides such a visual programming tool that you easily pick and play some pre-implemented blocks. Your task is to choose which dataset you prefer. But what is the YonoHub platform?</p> <blockquote> <p>Yonohub is the first cloud-based system for designing, sharing, and evaluating complex systems, such as Autonomous Vehicles, ADAS, and Robotics. Yonohub features a drag-and-drop tool to build complex systems consisting of many blocks, a marketplace to share and monetize blocks, a builder for custom environments, and much more.</p> </blockquote> <p>In this series of tutorials, we will go through a deep learning journey, especially <strong>Image Classification</strong>, starting from streaming a dataset till the deployment. The tutorials cover how to use Tensorflow in YonoHub by using the blocks offered within YonoArc.</p> <p>In this tutorial, we will see how to use the Tensorflow Datasets Player block (Image Classification category) within YonoArc. Covering the visualization of over 50 different image classification datasets streamed from a single block. We will use some utils blocks from the OpenCV package in YonoArc.</p> <h2 id="tensorflow-datasets-in-yonoarc">Tensorflow Datasets in YonoArc</h2> <p>Just a few steps and you run your first pipeline of YonoArc blocks. First of all, you need to <a href="https://app.yonohub.com/" rel="external nofollow noopener" target="_blank">signup</a> in YonoHub. After signing in, you will have some core Apps, in the Main View, which you can check them later one by one using the aid of the official <a href="https://yonohub.com/" rel="external nofollow noopener" target="_blank">website</a>.</p> <p align="center"> <img src="https://cdn-images-1.medium.com/max/2004/1*M88cYQCoIT2-JGAD0BhyeA.png" width="800px" title="Main View" alt="Main View"> </p> <p align="center"> Main View </p> <p>Let’s focus on YonoArc but first, you will need to freely purchase some necessary blocks. To do so you need to click on <a href="https://yonohub.com/yonostore/" rel="external nofollow noopener" target="_blank">YonoStore</a>,</p> <blockquote> <p>YonoStore is a marketplace for the state-of-the-art blocks, datasets, and ready-made runtime environments. YonoStore is fully accessible by both the online users and the users of any on-premises Yonohub, while still protecting everyone’s intellectual property.</p> </blockquote> <p>Follow YonoStore <a href="https://docs.yonohub.com/docs/yonohub/yonostore/" rel="external nofollow noopener" target="_blank">documentation</a> to purchase any product. For our tutorial, search for the following blocks,</p> <ul> <li> <p><a href="https://store.yonohub.com/product/image-classification-player/" rel="external nofollow noopener" target="_blank">Image Classification TFDS Player</a></p> </li> <li> <p><a href="https://store.yonohub.com/product/draw-label/" rel="external nofollow noopener" target="_blank">OpenCV Draw Label</a></p> </li> </ul> <p>After purchasing, let’s create a pipeline!</p> <h3 id="visualize-tensorflow-datasets">Visualize Tensorflow Datasets</h3> <p>In the next clip, we demonstrate how to create a pipeline and launch it. This pipeline aims to investigate the usage of the Image Classification TFDS Player by visualization various numbers of datasets for image classification.</p> <p align="center"> <a href="https://www.youtube.com/watch?v=-yspgvzk1Y8" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/-yspgvzk1Y8/0.jpg" width="800px" title="Visualize Tensorflow Datasets" alt="Visualize Tensorflow Datasets"></a> </p> <p align="center"> Visualize Tensorflow Datasets </p> <p>The clip shows the advantage of using YonoArc for datasets streaming. We visualized different datasets like beans and cifar10. Furthermore, the frame rate of the streaming has been changed in live mode. You do not need to terminate the full pipeline for that. But can we do more?</p> <h3 id="preprocess-and-draw-labels">Preprocess and Draw Labels</h3> <p>We need to interact with raw images as well as the labels by doing some preprocessing to prepare the training process for such a dataset. In the next clip, we illustrate how to create a custom block to simply resize the streamed images using <em>cv2.resize</em> function in python. Moreover, we draw the streamed labels on top of the resized image using the OpenCV Draw Label block we purchased early.</p> <p align="center"> <a href="https://www.youtube.com/watch?v=XQAEguGxWrk" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/XQAEguGxWrk/0.jpg" width="800px" title="Preprocess and Draw Labels" alt="Preprocess and Draw Labels"></a> </p> <p align="center"> Preprocess and Draw Labels </p> <p>Now you implement a full pipeline that streams, preprocesses, annotates, and visualizes the beans dataset. You implement a custom block to resize images.</p> <p>To learn more about creating blocks in YonoArc, check the <a href="https://docs.yonohub.com/docs/yonohub/yonoarc/creating-yonoarc-blocks/" rel="external nofollow noopener" target="_blank">docs</a>. You can check the article’s pipeline as well as the source codes for all the blocks used in this <a href="https://github.com/YonoHub/Introducing-TensorFlow-Datasets-in-YonoHub-Suit.git" rel="external nofollow noopener" target="_blank">repository</a>. Furthermore, you can purchase the <a href="https://store.yonohub.com/product/resize/" rel="external nofollow noopener" target="_blank">OpenCV Resize</a> block from YonoStore, it contains the same functionality as the one you implemented but with more features.</p> <h2 id="conclusion">Conclusion</h2> <p>Finally, you are ready to use the pipeline for training. In the next article, we will build a CNN model to classify the cifar10 dataset’s classes. The model will be implemented using Tensorflow V2.0 and encapsulated as a block in YonoArc. It’s easy to try out Yonohub. New users receive $25 free credits. Sign up on <a href="https://yonohub.com/" rel="external nofollow noopener" target="_blank">Yonohub</a>!</p> <h2 id="reference">Reference</h2> <p>[1] <a href="https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html" rel="external nofollow noopener" target="_blank">https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html</a></p> <p>[2] <a href="https://www.tensorflow.org/datasets/catalog/overview" rel="external nofollow noopener" target="_blank">https://www.tensorflow.org/datasets/catalog/overview</a></p> <p>[3] <a href="https://yonohub.com/" rel="external nofollow noopener" target="_blank">https://yonohub.com</a></p> <p>[4] <a href="https://docs.yonohub.com/" rel="external nofollow noopener" target="_blank">https://docs.yonohub.com</a></p> <h2 id="how-to-use-the-arc-file">How to Use the arc file?</h2> <p>You can follow the following steps to use the arc file of the demo directly in YonoArc and achieve the same results,</p> <ul> <li>Freely purchase all the required blocks from YonoStore.</li> <li>Clone the repository and upload the arc file to your YonoDrive.</li> <li>Click on the YonoArc application.</li> <li>Click File, then Open….</li> <li>Browse to the location of the saved arc file and select it.</li> </ul> <p>Now you have the same pipeline above, you can follow the rest of the tutorial to replicate the results.</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ahmed M. Hendawy. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: March 22, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>