<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Part 3 - Model Testing — Image Classification with YonoHub &amp; Tensorflow V2.0 Series | Ahmed M. Hendawy </title> <meta name="author" content="Ahmed M. Hendawy"> <meta name="description" content="Developing effective deep learning is not an easy task. The deep learning researchers are competing to benchmark their models against many datasets. One can design an object detection model for…"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8F%B9&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="ahmedhendawy.de/blog/2020/part3-imageclassification/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ahmed </span> M.  Hendawy </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Part 3 - Model Testing — Image Classification with YonoHub &amp; Tensorflow V2.0 Series</h1> <p class="post-meta"> August 09, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/image-classification"> <i class="fa-solid fa-hashtag fa-sm"></i> Image_Classification</a>   <a href="/blog/tag/tensorflow"> <i class="fa-solid fa-hashtag fa-sm"></i> Tensorflow</a>     ·   <a href="/blog/category/yonohub"> <i class="fa-solid fa-tag fa-sm"></i> Yonohub</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p align="center"> <a href="https://algotrading101.com/learn/what-is-overfitting-in-trading/" rel="external nofollow noopener" target="_blank"><img src="https://cdn-images-1.medium.com/max/2000/1*LC0B80A8Y6Y-YjxQ-J5MbQ.png" width="800px" title="Tensorflow Series" alt="Tensorflow Series"></a> </p> <p>Developing effective deep learning is not an easy task. The deep learning researchers are competing to benchmark their models against many datasets. One can design an object detection model for autonomous driving and benchmark it against Kitti, nuScenes, Waymo, etc.… Another one creates an image classification model and makes sure to achieve high performance against COCO, ImageNet, etc.… But why is that?</p> <p>Actually, it is not for a single reason; however, there is a motive, which drives all these eager researchers, which is reaching the generality of their model. To have a model that is not locally optimally according to the trained data provided is the target.</p> <p>Various problems need to be tackled to reach such a performance. One common challenge which is famous in the machine learning/ deep learning community is the overfitting. Your model is too complicated to the extend of memorizing all the answers from your training dataset.</p> <p>Many solutions have been provided to solve such an issue, starting from having much bigger data to regulate your training loop. However, a first step before solving the problem is to know how to detect it. As the chief needs to taste their food before serving, the deep learning developer needs to check the overfitting before serving the model as a solution for the targeted problem. Testing the model on a separated unseen dataset is the way to do so. If your model performs on the test dataset roughly similar, in terms of accuracy, on the training one, you are ready to go.</p> <p>This is why in this tutorial we wanted to cover how to do testing using a test split unseen by our trained model. Using the same pipeline from the previous <a href="https://medium.com/yonohub/part-2-model-implementation-training-image-classification-with-yonohub-tensorflow-v2-0-f74e72878e77" rel="external nofollow noopener" target="_blank">tutorial</a> with some slight changes discussed below to validate our model and check if there is overfitting or not.</p> <p>In this series of tutorials, we will go through a deep learning journey, especially for <strong>Image Classification</strong>, starting from streaming a dataset till the deployment. The tutorials cover how to use Tensorflow in Yonohub by using the blocks offered within YonoArc for a fast and easy way of development and deployment.</p> <h2 id="upgrading-the-model-yonoarc-block">Upgrading the Model YonoArc block</h2> <p>The training loop in YonoArc is divided into a dataset player and a model. Each implemented and encapsulated within a block. Similar to the previous tutorial the dataset player publishes the CIFAR-10 dataset continuously in batches with a specific frame rate. Previously, we chose the train split, however, this time a test split will be selected instead.</p> <p>The model block was by default operated in a training mode. A droplist is provided to select the operating mode of the model either for training or testing. For the newly added testing mode, we add similar functions for the block’s source code, <em>testing</em>, and <em>test_step</em> function as shown below,</p> <script src="https://gist.github.com/AhmedMagdyHendawy/eeccf2cc2ac39fa5571bbd546652b258.js"></script> <p>The functions are similar to the normal functions used by TensorFlow in addition to some pieces of code to publish the results to the user in terms of an INFO alert as well as port messages. We used the model parameters trained from the previous tutorial to be loaded and ready for testing.</p> <h2 id="tensorflow-testing-in-yonohub">TensorFlow Testing in Yonohub</h2> <p>You can follow the next video tutorial to replicate the steps required to perform the testing loop. However, you can download the .arc file of the pipeline and open it in YonoArc, from <a href="https://github.com/YonoHub/Model-Testing" rel="external nofollow noopener" target="_blank">here</a>, directly without worrying about even setting the above parameters. Although, you need to freely purchase all the blocks used in the article from YonoStore.</p> <p align="center"> <a href="https://www.youtube.com/watch?v=qDcUm8kyZQE" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/qDcUm8kyZQE/0.jpg" width="800px" title="Tensorflow Testing in Yonohub " alt="Tensorflow Testing in Yonohub "></a> </p> <p align="center"> Tensorflow Testing in Yonohub </p> <h2 id="conclusion">Conclusion</h2> <p>As the above video tutorial demonstrates, the percentage of the testing is approximately 71% which is very close to training accuracy from the previous tutorial. Now, our model is ready to be deployed on hardware to be tested in a real-life scenario.</p> <p>Using Yonoarc for testing facilitates the idea of validating your model against different real-life datasets by just replacing the Image Classification Dataset Player by any other dataset player to cover a larger distribution of data during testing of your trained model.</p> <h2 id="about-yonohub">About Yonohub</h2> <blockquote> <p><em>Yonohub is a web-based cloud system for development, evaluation, integration, and deployment of complex systems, including Artificial Intelligence, Autonomous Driving, and Robotics. Yonohub features a drag-and-drop tool to build complex systems, a marketplace to share and monetize blocks, a builder for custom development environments, and much more. YonoHub can be deployed on-premises and on-cloud.</em></p> </blockquote> <p>Get $25 free credits when you sign up now. For researchers and labs, contact us to learn more about Yonohub sponsorship options.</p> <p>If you liked this article, please consider following us on Twitter at <a href="https://twitter.com/YonoHub" rel="external nofollow noopener" target="_blank">@yonohub</a>, <a href="mailto:info@yonohub.com">email us directly</a>, or <a href="https://www.linkedin.com/showcase/yonohub" rel="external nofollow noopener" target="_blank">find us on LinkedIn</a>. I’d love to hear from you if I can help you or your team with how to use Yonohub.</p> <h2 id="references">References</h2> <p>[1] <a href="https://www.tensorflow.org/tutorials/images/cnn" rel="external nofollow noopener" target="_blank">https://www.tensorflow.org/tutorials/images/cnn</a></p> <h2 id="references-1">References</h2> <p>[1] <a href="https://www.tensorflow.org/tutorials/images/cnn" rel="external nofollow noopener" target="_blank">https://www.tensorflow.org/tutorials/images/cnn</a></p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ahmed M. Hendawy. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: March 22, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>