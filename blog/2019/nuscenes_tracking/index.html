<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Using YonoHub to Participate in the nuScenes Tracking Challenge | Ahmed M. Hendawy </title> <meta name="author" content="Ahmed M. Hendawy"> <meta name="description" content="The nuScenes package, in YonoArc, facilitates the participation in the nuScenes Tracking Challenge."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8F%B9&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="ahmedhendawy.de/blog/2019/nuscenes_tracking/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ahmed </span> M.  Hendawy </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Using YonoHub to Participate in the nuScenes Tracking Challenge</h1> <p class="post-meta"> December 02, 2019 </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/nuscenes"> <i class="fa-solid fa-hashtag fa-sm"></i> nuScenes</a>   <a href="/blog/tag/object-tracking"> <i class="fa-solid fa-hashtag fa-sm"></i> Object_Tracking</a>     ·   <a href="/blog/category/yonohub"> <i class="fa-solid fa-tag fa-sm"></i> Yonohub</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p align="center"> <a href="https://www.youtube.com/watch?v=6qslqVRR2kM" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/6qslqVRR2kM/0.jpg" width="800px" title="nuScenes Package Overview" alt="nuScenes Package Overview"></a> </p> <p align="center"> nuScenes Package Overview </p> <p>A large-scale dataset, which is called <a href="https://www.nuscenes.org" rel="external nofollow noopener" target="_blank">nuScenes</a>, was published by Aptiv Autonomous Mobility (formerly nuTonomy) on the 27th of March 2019, to help the autonomous driving community during the development, and evaluation stages. nuScenes dataset is one of the most promising datasets which facilitate the developing of new autonomous driving algorithms for 3D object detection and 3D object tracking as well.</p> <p>Consequently, the nuScenes team organized a <a href="https://www.nuscenes.org/object-detection?externalData=all&amp;mapData=all&amp;modalities=Any" rel="external nofollow noopener" target="_blank">3D Object Detection Challenge</a> at the last CVPR conference. This challenge aimed to motivate the developers, in the field of the autonomous driving, to benchmark their 3D object detections algorithm against the nuScenes dataset.</p> <p>After the success of the 3D Object Detection challenge, another challenge is recently organized for <a href="https://www.nuscenes.org/tracking?externalData=all&amp;mapData=all&amp;modalities=Any" rel="external nofollow noopener" target="_blank">3D Object Tracking</a>. It will be held during the next NIPS conference.</p> <p>At the same time, the <a href="https://yonohub.com/" rel="external nofollow noopener" target="_blank">YonoHub</a> team has created a nuScenes package that can be used inside the YonoHub platform. The package is in the form of blocks that encapsulate specific functions. The package is used within the main YonoHub application, <a href="https://yonohub.com/yonoarc/" rel="external nofollow noopener" target="_blank">YonoArc</a>. In addition, the nuScenes dataset is available as an extracted version on this cloud-based platform, you do not need to download the dataset with this huge size. You can freely purchase the dataset from <a href="https://store.yonohub.com" rel="external nofollow noopener" target="_blank">YonoStore</a> as well as all the nuScenes package blocks.</p> <p>Accordingly, the nuScenes package became a new method to benchmark your algorithm against the nuScenes dataset for the upcoming nuScenes Tracking Challenge. Just by drag and drop some blocks, you will be able to interact with the dataset.</p> <p>In addition to the blocks, Yonohub provides sponsored credits (up to $1000) to work on nuScenes 3D Tracking Challenge. Apply using <a href="https://yonohub.com/nuscenes-package-and-sponsorship/" rel="external nofollow noopener" target="_blank">this form</a> to receive the sponsored credits directly in your account.</p> <p>Let’s discuss how can you start working with the package!</p> <h2 id="how-does-it-work">How does it work?</h2> <p>As a first step, you need to get the nuScenes dataset as well as the nuScenes blocks for YonoArc development. YonoStore is the place where you can purchase a dataset, block, or even environment. There are different datasets other than nuScenes, for example, Kitti Dataset, Comma.ai, etc..</p> <p>After purchasing the assets, you will find the nuScenes Dataset in your YonoStoreDataset folder, however, the nuScenes blocks in your YonoArc blocks.</p> <p>The nuScenes package enriches of different kinds of blocks. The last update of the package consists of 10 blocks as listed below,</p> <ul> <li> <p><strong>Dataset Player</strong>: used to stream all the sample data for all kinds of sensors as well as the metadata of the nuScenes dataset.</p> </li> <li> <p><strong>Sample Annotations to Eval Boxes</strong>: used to convert the sample annotation box format to eval box format.</p> </li> <li> <p><strong>Boxes Frame Transformer</strong>: used to transform the reference frame of the boxes to another one.</p> </li> <li> <p><strong>Lidar Point Cloud Converter</strong>: <em>**</em>used to convert the reference frame of the lidar point cloud from nuScenes lidar frame to Kitti lidar frame or vice versa.</p> </li> <li> <p><strong>Eval Boxes Preprocessing</strong>: <em>**</em>used to perform the preprocessing over the eval boxes before the evaluation process.</p> </li> <li> <p><strong>Predictions Appender</strong>: used to append/ batch all the predicted boxes as a JSON file for submission.</p> </li> <li> <p><strong>Predictions Loader</strong>: used to load the results saved as JSON file for the evaluation/visualization process.</p> </li> <li> <p><strong>Tracking Benchmark</strong>: used to perform the tracking evaluation bench-marking of the predicted boxes against the ground truth boxes from the dataset.</p> </li> <li> <p><strong>Boxes to Markers</strong>: used to convert the boxes to markers format for proper visualization in <a href="http://wiki.ros.org/rviz" rel="external nofollow noopener" target="_blank">Rviz</a> (Purchase Rviz block from YonoStore).</p> </li> <li> <p><strong>Draw 3D Boxes</strong>: used to draw the boxes over one of the camera output images.</p> </li> </ul> <p>NOTE: To learn more about the block’s settings, functionality, as well as input/output ports, check the description associated with the item in YonoStore or through the Help tab in the block’s settings in YonoArc.</p> <p>After reading the brief description of each block in the package, we need to illustrate how to use it in YonoArc. We can check the following series of tutorial videos which are very useful to understand the bench-marking cycle in YonoArc. For a more detailed description regarding the following tutorials, please read the corresponding tutorial in the <a href="https://docs.yonohub.com/docs/yonohub/nuscenes-package/" rel="external nofollow noopener" target="_blank">docs</a>.</p> <h3 id="getting-started-with-nuscenes">Getting Started with nuScenes</h3> <p>In this tutorial, we learn how to interact with the nuScenes dataset through the Dataset Player block. Streaming the raw images of one of the dataset’s camera sensors and visualize it using the Dashboard in YonoArc.</p> <p align="center"> <a href="https://www.youtube.com/watch?v=jLYU5-gqp9Y" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/jLYU5-gqp9Y/0.jpg" width="800px" title="Tutorial 1: Getting Started with nuScenes " alt="Tutorial 1: Getting Started with nuScenes"></a> </p> <p align="center"> Tutorial 1: Getting Started with nuScenes </p> <h3 id="visualize-the-nuscenes-dataset">Visualize the nuScenes Dataset</h3> <p>In this tutorial, we deal with the different visualization methods, which are offered through the nuScenes package in YonoArc. At the end of this tutorial, you learn how to,</p> <ul> <li> <p>Draw the 3D Ground Truth Boxes on the raw images captured by Camera sensors.</p> </li> <li> <p>Visualize the Radar/Lidar point cloud in Rviz with a different number of sweeps.</p> </li> <li> <p>Convert the 3D Ground Truth Boxes to <a href="http://docs.ros.org/melodic/api/visualization_msgs/html/msg/Marker.html" rel="external nofollow noopener" target="_blank">Markers</a> to visualize it in Rviz on the top of the Lidar point cloud.</p> </li> </ul> <p align="center"> <a href="https://www.youtube.com/watch?v=XWoKT2rp1ck" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/XWoKT2rp1ck/0.jpg" width="800px" title="Tutorial 2: Visualize the nuScenes Dataset" alt="Tutorial 2: Visualize the nuScenes Dataset"></a> </p> <p align="center"> Tutorial 2: Visualize the nuScenes Dataset </p> <h3 id="predict-and-save-your-results">Predict and Save Your Results</h3> <p>In this tutorial, you take your first steps regarding the involvement in the nuScenes Tracking Challenge. At the end of this tutorial, you learn how to,</p> <ul> <li> <p>Load the detection results of one of the <a href="https://www.nuscenes.org/tracking/#baselines" rel="external nofollow noopener" target="_blank">supported algorithms</a> by the nuScenes Challenge, for example, MEGVII.</p> </li> <li> <p>Use a pre-implemented tracking algorithm like AB3DMOT. You can develop your own algorithm as a YonoArc block using <a href="https://docs.yonohub.com/docs/yonohub/tutorials/custom-python3-block/" rel="external nofollow noopener" target="_blank">this</a> tutorial.</p> </li> <li> <p>Append your results after doing the preprocessing stage as a JSON file with the same nuScenes Tracking Challenge format.</p> </li> </ul> <p>NOTE: You can purchase the AB3DMOT tracking algorithm from YonoStore.</p> <p align="center"> <a href="https://www.youtube.com/watch?v=ZZEltqiXgao" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/ZZEltqiXgao/0.jpg" width="800px" title="Tutorial 3: Predict and Save Your Results " alt="Tutorial 3: Predict and Save Your Results "></a> </p> <p align="center"> Tutorial 3: Predict and Save Your Results </p> <h3 id="benchmark-your-tracking-algorithm">Benchmark Your Tracking Algorithm</h3> <p>In this final tutorial, we construct an evaluation/bench-marking loop for the challenge. At the end of this tutorial, you learn how to,</p> <ul> <li> <p>Load your own tracking results from the previous tutorial.</p> </li> <li> <p>Benchmark your algorithm against the nuScenes Dataset.</p> </li> </ul> <p align="center"> <a href="https://www.youtube.com/watch?v=nCp-T6JIynw" rel="external nofollow noopener" target="_blank"><img src="http://img.youtube.com/vi/nCp-T6JIynw/0.jpg" width="800px" title="Tutorial 4: Benchmark Your Algorithm" alt="Tutorial 4: Benchmark Your Algorithm"></a></p> <p align="center"> Tutorial 4: Benchmark Your Algorithm </p> <p>NOTE: You can find all the previous YonoArc pipelines in <a href="https://gitlab.yonohub.com/YonoTeam/nuscenes_package_tutorials" rel="external nofollow noopener" target="_blank">this</a> repository.</p> <h2 id="conclusion">Conclusion</h2> <p>Finally, you are ready to participate in the nuScenes Tracking Challenge with an easy-to-use drag and drop interface. You do not need to download this huge sized dataset on your local machine, just freely purchase the dataset and you get it in no time. All the development can be done on YonoHub using different machine capabilities.</p> <p>It’s easy to try out Yonohub. New users receive $50 free credits. For nuScenes Challenges, Yonohub provides sponsored credits (up to $1000) to work on nuScenes 3D Tracking Challenge. Apply using <a href="https://yonohub.com/nuscenes-package-and-sponsorship/" rel="external nofollow noopener" target="_blank">this form</a> to receive the sponsored credits directly in your account. Sign up on Yonohub!</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ahmed M. Hendawy. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: March 22, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>