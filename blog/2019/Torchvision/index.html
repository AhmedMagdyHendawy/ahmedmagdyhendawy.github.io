<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Image Classification using Torchvision Pre-trained Models in a Single YonoArc Block | Ahmed M. Hendawy </title> <meta name="author" content="Ahmed M. Hendawy"> <meta name="description" content="YonoHub series of tutorials which mimic the PyTorch for Beginners tutorials in a single reusable block."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8F%B9&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="ahmedhendawy.de/blog/2019/Torchvision/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ahmed </span> M.  Hendawy </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Image Classification using Torchvision Pre-trained Models in a Single YonoArc Block</h1> <p class="post-meta"> September 25, 2019 </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/image-classification"> <i class="fa-solid fa-hashtag fa-sm"></i> Image_Classification</a>   <a href="/blog/tag/torchvision"> <i class="fa-solid fa-hashtag fa-sm"></i> Torchvision</a>     ·   <a href="/blog/category/yonohub"> <i class="fa-solid fa-tag fa-sm"></i> Yonohub</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p align="center"> <img src="https://cdn-images-1.medium.com/max/2724/1*4qKMqWYD401zdUPsptB8lA.jpeg" width="800px" title="Overview" alt="Overview"> </p> <p>Recently, I decided to learn how to implement machine learning (ML) algorithms, especially in the computer vision field, using the well-known package <a href="https://pytorch.org" rel="external nofollow noopener" target="_blank"><strong>Pytorch</strong></a>. One of the useful resources, to break the ice with such a powerful ML package, is the <a href="https://www.learnopencv.com/learn-pytorch/" rel="external nofollow noopener" target="_blank"><strong>PyTorch for Beginners</strong></a> series of tutorials offered by <a href="https://www.learnopencv.com" rel="external nofollow noopener" target="_blank"><strong>Learn OpenCV</strong></a>. The series contains some core topics that should be understood by the computer vision developers who are using Pytorch.</p> <p>I follow the second tutorial with the title: <a href="https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/" rel="external nofollow noopener" target="_blank"><strong>PyTorch for Beginners: Image Classification using Pre-trained models</strong></a>. I am surprised by the amount of the architectures supported by the <a href="https://pytorch.org/docs/stable/torchvision/index.html" rel="external nofollow noopener" target="_blank"><strong>Torchvision</strong></a> module for image classification.</p> <blockquote> <p><strong>Torchvision</strong> package consists of popular datasets, model architectures, and common image transformations for computer vision. Basically, if you are into Computer Vision and using PyTorch, Torchvision will be of great help!</p> </blockquote> <p>I thought it will be a beneficial idea to use YonoArc App in the <a href="https://yonohub.com" rel="external nofollow noopener" target="_blank"><strong>YonoHub</strong></a> platform to encapsulate all the supported image classification architectures, by torchvision package, in a single block. The developers will have the facility of using only one YonoArc block to evaluate and benchmark the different performances of the well-known classifiers with its pre-trained weights.</p> <blockquote> <p><strong>YonoHub</strong> is the first cloud-based system for designing, sharing, and evaluating complex systems, such as Autonomous Vehicles, ADAS, and Robotics. Yonohub features a drag-and-drop tool to build complex systems consisting of many blocks, a marketplace to share and monetize blocks, a builder for custom environments, and much more.</p> </blockquote> <h2 id="how-does-the-block-work">How does the block work?</h2> <p>To have a good hand-on example, I use in the following demo the nuScenes dataset which can be streamed in the YonoArc pipeline using its supported player block. For more information about nuScenes-YonoArc package, you can read my previous article <a href="https://medium.com/@ahmedmagdyattia1996/nuscenes-using-yonohub-to-develop-evaluate-and-benchmark-over-the-cloud-94c06685c168" rel="external nofollow noopener" target="_blank">here</a>.</p> <p align="center"> <img src="https://cdn-images-1.medium.com/max/2592/1*Otk5RtkP7NVDhZ-qYBtUAA.jpeg" width="800px" title="Image Classification Demo" alt="Image Classification Demo"> </p> <p align="center"> Image Classification Demo </p> <p><strong>Torchvision Image Classifier</strong> YonoArc block has one input which intuitively of type Image. The source of the input images is the <strong>nuScenes Dataset Player</strong> as shown above. On the other hand, the block has two different outputs. The first output port is an image after writing the classes that the model is certain about. The other port is the classes associated with its confidence that the model predicted. The type of this output port is a custom ROS message which is included in the <a href="https://gitlab.yonohub.com/AhmedHendawy/perception-msgs" rel="external nofollow noopener" target="_blank"><strong>perception_msgs</strong></a> package I implemented for interacting with the YonoArc blocks in the field of computer vision.</p> <p>The image classifier block has a property of choosing the model which you want to evaluate. As shown below, you have a drop list, under the title <strong>Model</strong> **Options, **with 31 different image classification models. You can reach this drop list by clicking on the setting icon of the block.</p> <p align="center"> <img src="https://cdn-images-1.medium.com/max/2594/1*fHJC3qdYWbYsa7ae0U35Cg.png" width="800px" title="Image Classification Model Options" alt="Image Classification Model Options"> </p> <p align="center"> Image Classification Model Options </p> <p>One great thing about YonoArc is that each block can use different resource models in the same pipeline. For example, the image classifier block uses GPU as a resource model. However, an eight-core CPU is the resource model of both the nuScenes player and the video viewer blocks.</p> <h2 id="source-code">Source Code</h2> <p>During the implementation of the presented block, I make use of the LearnOpenCV tutorial code. I manipulate it to be general and suitable for the YonoArc blocks code structure. <a href="https://docs.yonohub.com" rel="external nofollow noopener" target="_blank"><strong>YonoHub Docs</strong></a> is very useful to understand how to make a python 3 API YonoArc block. You can read this <a href="https://docs.yonohub.com/docs/yonohub/yonoarc/yonoarc-python3-api/" rel="external nofollow noopener" target="_blank">part</a> of the docs to understand the changes happen to the tutorial code. You can check the source code below,</p> <script src="https://gist.github.com/AhmedMagdyHendawy/a002b062dcde6d3111257019b62dfad4.js"></script> <h2 id="results">Results</h2> <p>After running the above pipeline, the below results have been produced. AlexNet model is chosen to predict the shown estimated classes.</p> <p align="center"> <img src="https://cdn-images-1.medium.com/max/2000/1*-lvQb1kJ4zxnLdBR3CTnkw.gif" width="800px" title="Image Classification Results" alt="Image Classification Results"> </p> <p align="center"> Image Classification Results </p> <p>Finally, I tried to demonstrate how to use YonoArc App in the YonoHub platform to implement the image classification tutorial by Learn OpenCV. Merging the benefits of both Pytorch, especially Torchvision, and YonoArc App to have an encapsulated image classification library of models in the shape of a block. You can purchase the <strong>Torchvision Image Classifier</strong> block for free, through <a href="https://store.yonohub.com/product/torchvision-image-classifier/" rel="external nofollow noopener" target="_blank"><strong>YonoStore</strong></a>, and try the different models available without dealing with the code details. In addition, you can clone the above source code from <a href="https://gitlab.yonohub.com/AhmedHendawy/torchvision_image_classifier" rel="external nofollow noopener" target="_blank">here</a> to reuse it for such blocks. Follow the steps in the referred <a href="https://docs.yonohub.com/docs/yonohub/tutorials/custom-python3-block/" rel="external nofollow noopener" target="_blank">tutorial</a> to learn how to implement a YonoArc block.</p> <p>Next, I will work on the semantic segmentation tutorial to have a similar reusable YonoArc block. It’s easy to try out Yonohub. New users receive $25 free credits. Sign up on <a href="https://yonohub.com/" rel="external nofollow noopener" target="_blank">Yonohub</a>!</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ahmed M. Hendawy. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: June 02, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>